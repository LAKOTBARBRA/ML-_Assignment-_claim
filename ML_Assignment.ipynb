{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mME8cMsEI-PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.metrics import RocCurveDisplay, auc\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "#loading the training dataset\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/dataset/train_data.csv')"
      ],
      "metadata": {
        "id": "_t5M5XSSOK6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "id": "vI6lBEyzF2yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset has 7160 rows and 14 columns"
      ],
      "metadata": {
        "id": "HEOMrX0dNjDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying the columns in the dataset\n",
        "df1.columns"
      ],
      "metadata": {
        "id": "LEDXv8EGpvbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#viewing the first five rows of the dataset\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "NQcDXfL0NWG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows that the dataset has 7160 rows"
      ],
      "metadata": {
        "id": "nuycDwXrRXO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying the datatype\n",
        "df1.info()"
      ],
      "metadata": {
        "id": "Qrd71gTlUeC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows that out of the 14 columns, 3 contains float datatype, 4 has integer and 7 columns conatin strings as a datatype and that means there need for encoding the categorical variables"
      ],
      "metadata": {
        "id": "of-kaufOX22Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying basic key statistics\n",
        "df1.describe()"
      ],
      "metadata": {
        "id": "dMhQQgeCXtJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying basic key statistics\n",
        "df1.describe(include=object)"
      ],
      "metadata": {
        "id": "BlnyRFlKOp-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for missing values in the dataset\n",
        "df1.isna().sum()"
      ],
      "metadata": {
        "id": "34QnV8swqmEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variable Garden has 7 missing values, Building Dimension has 106, Date_of_occupancy has 508 and Geo_code has 102 missing values.\n"
      ],
      "metadata": {
        "id": "N-oiZw2o0h3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling the missing values using imputation since the dataset is small\n",
        "df1 = df1\n",
        "df1['Building Dimension']=df1['Building Dimension'].fillna(df1['Building Dimension'].median())\n",
        "df1['Date_of_Occupancy']=df1['Date_of_Occupancy'].fillna(df1['Date_of_Occupancy'].median())\n",
        "df1['Garden']=df1['Garden'].fillna(df1['Garden'].mode().iloc[0])\n",
        "df1['Geo_Code']=df1['Geo_Code'].fillna(df1['Geo_Code'].mode().iloc[0])\n",
        "df1.info()"
      ],
      "metadata": {
        "id": "xQYzdHrAqmHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows that all the missing values have been handled since all variables have total count of 7160"
      ],
      "metadata": {
        "id": "0W8UcjhEtNFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n"
      ],
      "metadata": {
        "id": "ASJArqu3XeTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution of the data"
      ],
      "metadata": {
        "id": "1BJH2ETwXr7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns\n"
      ],
      "metadata": {
        "id": "B-lg8JIwy58I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Building Dimension'].describe()"
      ],
      "metadata": {
        "id": "Z_oXkj7DfVq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing outlier\n",
        "upper_limit = df1['Building Dimension'].mean() + 0.7*df1['Building Dimension'].std()\n",
        "lower_limit = df1['Building Dimension'].mean() - 0.7*df1['Building Dimension'].std()"
      ],
      "metadata": {
        "id": "dmll4Tnlfzg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Upper_limit:',upper_limit)\n",
        "print('Lower_limit:',lower_limit)"
      ],
      "metadata": {
        "id": "sZWUC5vzhEu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(df1['Building Dimension'])\n",
        "plt.title('Histogram for the distribution of Building Dimension for df1')\n",
        "plt.xlabel('Building Dimension')\n",
        "plt.ylabel('Frequency')"
      ],
      "metadata": {
        "id": "p3n9iCgwiCVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff1=df1.loc[(df1['Building Dimension']<upper_limit) & (df1['Building Dimension']>lower_limit)]\n",
        "dff1['Building Dimension'].describe()"
      ],
      "metadata": {
        "id": "3H1uJ-FriwUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(dff1['Building Dimension'])\n",
        "plt.title('Histogram for the distribution of Building Dimension for df1')\n",
        "plt.xlabel('Building Dimension')\n",
        "plt.ylabel('Frequency')"
      ],
      "metadata": {
        "id": "Eujftcijj-z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "#from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# Load the California Housing dataset\n",
        "#data = fetch_california_housing(as_frame=True)\n",
        "#df1 = df1['data']\n",
        "#df['MedHouseVal'] = data['target']\n",
        "\n",
        "# Create a 4x2 grid of subplots\n",
        "fig, ax = plt.subplots(4, 2,figsize=(10, 10))\n",
        "\n",
        "# Plot histograms on each subplot\n",
        "#ax[0, 0].hist(df1['Customer Id'], bins=\"auto\")\n",
        "ax[0, 1].hist(df1['YearOfObservation'], bins=\"auto\")\n",
        "ax[1, 0].hist(df1['Insured_Period'], bins=\"auto\")\n",
        "ax[1, 1].hist(df1['Residential'], bins=\"auto\")\n",
        "ax[2, 0].hist(df1['Building_Painted'], bins=\"auto\")\n",
        "ax[2, 1].hist(df1['Building_Fenced'], bins=\"auto\")\n",
        "ax[3, 0].hist(df1['Garden'], bins=\"auto\")\n",
        "ax[3, 0].hist(df1['Building Dimension'], bins=\"auto\")\n",
        "\n",
        "# Set titles for each subplot\n",
        "ax[0, 0].set_title('Customer Id')\n",
        "ax[0, 1].set_title('YearOfObservation')\n",
        "ax[1, 0].set_title('Insured_Period')\n",
        "ax[1, 1].set_title('Residential')\n",
        "ax[2, 0].set_title('Building_Painted')\n",
        "ax[2, 1].set_title('Building_Fenced')\n",
        "ax[3, 0].set_title('Garden')\n",
        "ax[3, 0].set_title('Building Dimension')\n",
        "\n",
        "\n",
        "# Remove the empty subplot in the last row and last column\n",
        "fig.delaxes(ax[3, 1])\n",
        "\n",
        "# Adjust the spacing between subplots\n",
        "fig.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "41v_8Szwy1Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(3,3))\n",
        "plt.hist(df1[\"YearOfObservation\"])\n",
        "plt.xlabel(\"Years\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Histogram showing the distribution of YearOfObservation\")\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.hist(df1[\"Insured_Period\"])\n",
        "plt.xlabel(\"\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution pf Insured period\")\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.hist(df1[\"Residential\"])\n",
        "plt.xlabel(\"\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution od Residential\")"
      ],
      "metadata": {
        "id": "12qMJUPgXz9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of Attrition\n",
        "df1[\"Claim\"].value_counts()"
      ],
      "metadata": {
        "id": "jvBGU07phgWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(3,3))\n",
        "plt.rc(\"font\",size=8)\n",
        "sns.countplot(x='Claim',data=df1)\n",
        "plt.title(\"A bar graph showing the distribution of claim\")"
      ],
      "metadata": {
        "id": "vjdm5Ld1fyyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pie chart for attrition\n",
        "claim_counts = df1[\"Claim\"].value_counts()\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.pie(claim_counts, labels=claim_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.title('A pie chart showing the distribution of claim')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7I1dZuUdYs9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means 22.8% of the building has atleast one claim over the insured period and 77.2% has no claim over the insured period."
      ],
      "metadata": {
        "id": "xgpkACJEZnRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1[\"Building_Painted\"].value_counts()"
      ],
      "metadata": {
        "id": "aUo1YRNwn-Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[\"Building_Painted\"].value_counts()\n",
        "Building_Painted_counts = df1[\"Building_Painted\"].value_counts()\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.pie(Building_Painted_counts, labels=claim_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.title('A pie chart showing the distribution of Building_Painted')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VaVoLqySn_GU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[\"Building_Fenced\"].value_counts()"
      ],
      "metadata": {
        "id": "DM3QefyrnSqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[\"Building_Fenced\"].value_counts()\n",
        "Building_Fenced_counts = df1[\"Building_Fenced\"].value_counts()\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.pie(Building_Fenced_counts, labels=claim_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.title('A pie chart showing the distribution of Building_Fenced')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "A-RikJL7n2Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[\"Garden\"].value_counts()"
      ],
      "metadata": {
        "id": "ob-lM1NMnUJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[\"Garden\"].value_counts()\n",
        "Garden_counts = df1[\"Garden\"].value_counts()\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.pie(Garden_counts, labels=claim_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.title('A pie chart showing the distribution of Garden')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lh4ol7J2pRDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Claim with respect to Building_Painted\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.countplot(x='Building_Painted',hue='Claim',data=df1, palette='hot')\n",
        "plt.title( 'Claim VS Building_Painted')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K2XbUHh_pLp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQvtG8D4riMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "FBR-3dY0qf-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Claim with respect to Building_Type\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.countplot(x='Building_Type',hue='Claim',data=df1, palette='hot')\n",
        "plt.title( 'Claim VS Building_Type')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YJIu8H_pqbuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['Customer Id','NumberOfWindows','Geo_Code']\n",
        "df1 = df1.drop(columns=columns_to_drop, axis=1)"
      ],
      "metadata": {
        "id": "4fDPGQaMx-73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "v3IDx-fQyY7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5K3Uc3-M0CAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary Encoding"
      ],
      "metadata": {
        "id": "W5g1w82r0JpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data[\"Customer Id\"] = data[\"Customer Id\"].map({\"No\": 0, \"Yes\": 1})\n",
        "df1[\"Building_Painted\"] = df1[\"Building_Painted\"].map({\"N\": 0, \"V\": 1})\n",
        "df1[\"Building_Fenced\"] =df1[\"Building_Fenced\"].map({\"N\": 0, \"V\": 1})\n",
        "df1[\"Garden\"] = df1[\"Garden\"].map({\"V\": 0, \"O\": 1})\n",
        "df1[\"Settlement\"] = df1[\"Settlement\"].map({\"U\": 0, \"R\": 1})\n",
        "#data[\"NumberOfWindows\"] = data[\"NumberOfWindows\"].map({\"No\": 0, \"Yes\": 1})\n",
        "#data[\"Geo_Code\"] = data[\"Geo_Code\"].map({\"No\": 0, \"Yes\": 1})"
      ],
      "metadata": {
        "id": "f6veiB_FoyTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "FkSxf62SwIVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection"
      ],
      "metadata": {
        "id": "gntOp_ukwifJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "correlation_matrix = df1.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "i5J0qkcnwhCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_variable = 'Claim'\n",
        "correlation_with_target = correlation_matrix[target_variable]\n",
        "sorted_correlation = correlation_with_target.abs().sort_values(ascending=False)\n",
        "print(sorted_correlation)"
      ],
      "metadata": {
        "id": "65HhiyNNwhFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building Dimension is a feature of high importance, It has a positive correlation, this means that as the 'Building Dimension' increases, the likelihood of a claim being made also increases."
      ],
      "metadata": {
        "id": "nc-qYl-F-ywR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling the test dataset"
      ],
      "metadata": {
        "id": "L5cz20hhDfZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "#loading the test dataset\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/dataset/test_data.csv')"
      ],
      "metadata": {
        "id": "tONkFHBAwhHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying the columns in the dataset\n",
        "df2.columns"
      ],
      "metadata": {
        "id": "-rtGke7wwhKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying the first five rows\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "REvo4qVmwhNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#determining the dimension of the dataset\n",
        "df2.shape"
      ],
      "metadata": {
        "id": "8udg5kgACqeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows that the test dataset has 3069 rows and 13 columns"
      ],
      "metadata": {
        "id": "42SPLgx5Drfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.info()"
      ],
      "metadata": {
        "id": "2TsHrYUiCqgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows that out of the 13 columns, 3 columns have float datatype, 3 hae integer datatype and 7 columns have a string datatype."
      ],
      "metadata": {
        "id": "hyWGwOgzEVJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.describe()"
      ],
      "metadata": {
        "id": "vqvrzIn8Cqjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.describe(include=object)"
      ],
      "metadata": {
        "id": "5sXRZkp5CqnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for missing values in the dataset\n",
        "df2.isna().sum()"
      ],
      "metadata": {
        "id": "JQ95ZJTQCqqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling the missing values using imputation since the dataset is small\n",
        "df2 = df2\n",
        "df2['Building Dimension']=df2['Building Dimension'].fillna(df2['Building Dimension'].median())\n",
        "df2['Date_of_Occupancy']=df2['Date_of_Occupancy'].fillna(df2['Date_of_Occupancy'].median())\n",
        "df2['Garden']=df2['Garden'].fillna(df2['Garden'].mode().iloc[0])\n",
        "df2['Geo_Code']=df2['Geo_Code'].fillna(df2['Geo_Code'].mode().iloc[0])\n",
        "df2.info()"
      ],
      "metadata": {
        "id": "c0SsvCzSF1TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['Customer Id','NumberOfWindows','Geo_Code']\n",
        "df2 = df2.drop(columns=columns_to_drop, axis=1)"
      ],
      "metadata": {
        "id": "Av1VdaGtGP4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.columns"
      ],
      "metadata": {
        "id": "c-B_MYegGP9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary Encoding"
      ],
      "metadata": {
        "id": "HdJPEPVzG6Q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2[\"Building_Painted\"] = df2[\"Building_Painted\"].map({\"N\": 0, \"V\": 1})\n",
        "df2[\"Building_Fenced\"] =df2[\"Building_Fenced\"].map({\"N\": 0, \"V\": 1})\n",
        "df2[\"Garden\"] =df2[\"Garden\"].map({\"V\": 0, \"O\": 1})\n",
        "df2[\"Settlement\"] =df2[\"Settlement\"].map({\"U\": 0, \"R\": 1})\n"
      ],
      "metadata": {
        "id": "zTgSL4JtGP_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "yQr1Zn5IGQDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#scaler = StandardScaler()\n",
        "#X = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "TL8ZLRKLwgfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building\n"
      ],
      "metadata": {
        "id": "JO840TAlJ00b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the training dataset"
      ],
      "metadata": {
        "id": "EjxF6CXT6HlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming df1 is your DataFrame\n",
        "features = ['YearOfObservation', 'Insured_Period', 'Residential', 'Building_Painted', 'Building_Fenced', 'Garden', 'Settlement', 'Building Dimension', 'Building_Type', 'Date_of_Occupancy']\n",
        "target = \"Claim\"\n",
        "\n",
        "X = df1[features]\n",
        "y = df1[target]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "JF2ERoOsr66J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM Model"
      ],
      "metadata": {
        "id": "AcyuNZsa6BxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "clf = svm.SVC(kernel='rbf')\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "#print(\"Accuracy:\", accuracy)\n",
        "# Evaluating the SVM model using classification report\n",
        "print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "id": "Xf3_cgdpwe4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model's performance using a confusion matrix\n",
        "cm_svm = confusion_matrix(y_test,predictions)\n",
        "print(cm_svm)\n",
        "accuracy_score(y_test, predictions)"
      ],
      "metadata": {
        "id": "JCMs7sBDOfoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set (rc = {'figure.figsize':(4, 4)})\n",
        "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', cbar=False)"
      ],
      "metadata": {
        "id": "u23htOEUOu9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation of the models's performance on an ROC/AUC curve\n",
        "plt.figure(figsize=(5,4))\n",
        "svm = SVC(probability=True)\n",
        "\n",
        "# Train the model\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Visualize the ROC curve\n",
        "plt.figure(figsize=(5, 4))\n",
        "# Use decision_function to get decision values\n",
        "y_decision = svm.decision_function(X_test)\n",
        "\n",
        "# Manually compute probabilities using decision values\n",
        "y_pred_prob = (y_decision - y_decision.min()) / (y_decision.max() - y_decision.min())\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "nb_roc_auc2=roc_auc_score(y_test,svm.predict(X_test))\n",
        "plt.plot(fpr, tpr, label='Support Vector Classifier')\n",
        "plt.plot([0,1],[0,1],'r--')\n",
        "plt.xlim([0.0,1.0])\n",
        "plt.ylim([0.0,1.05])\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('ROC Curve for Support Vector Classifier')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WMAPi-b_O_9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression"
      ],
      "metadata": {
        "id": "ty6oK7W05-HD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# creating a object\n",
        "regressor = LinearRegression()\n",
        "#training the model\n",
        "regressor.fit(X, y)\n",
        "#using the training dataset for the prediction\n",
        "pred = regressor.predict(X)\n",
        "#model performance\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "mse = mean_squared_error(y, pred)\n",
        "r2 = r2_score(y, pred)#Best fit lineplt.scatter(x, y)\n",
        "#plt.plot(X, pred, color = 'Black', marker = 'o')\n",
        "#Results\n",
        "print(\"Mean Squared Error : \", mse)\n",
        "print(\"R-Squared :\" , r2)\n",
        "print(\"Y-intercept :\"  , regressor.intercept_)\n",
        "print(\"Slope :\" , regressor.coef_)"
      ],
      "metadata": {
        "id": "lb9ClwsQ3lFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tunning"
      ],
      "metadata": {
        "id": "Ko91jpRETHdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LinearRegression()\n",
        "\n",
        "# Define the hyperparameters and their possible values to search\n",
        "param_grid = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'positive': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV with the Linear Regression model and parameter grid\n",
        "grid_search = GridSearchCV(lr_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the model to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_lr_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_lr_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y, pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R-Squared :\" , r2)"
      ],
      "metadata": {
        "id": "BvNA642xTGX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3gwKvN5n3pFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "KNN Model\n",
        "\n"
      ],
      "metadata": {
        "id": "N3r_lbUy6Q16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Create the K-nearest Neighbours Classifier and use the train dataset to train the model\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "#predicting the model\n",
        "y_pred = knn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# Evaluating the K-nearest Neighbours model using classification report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "kAJEEp973wqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_2GOy9XqYxKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model's performance using a confusion matrix\n",
        "cm_knn = confusion_matrix(y_test, y_pred)\n",
        "print(cm_knn)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "bh-OOSRlJ8oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set (rc = {'figure.figsize':(4, 4)})\n",
        "sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Blues', cbar=False)"
      ],
      "metadata": {
        "id": "TXSy_Aq3LYFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation of the models's performance on an ROC/AUC curve\n",
        "plt.figure(figsize=(5,4))\n",
        "y_pred_= knn.predict_proba(X_test)[:,1]\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc_score_knn = roc_auc_score(y_test, y_pred)\n",
        "plt.plot(fpr, tpr, label='K-nearest Neighbours Classifier')\n",
        "plt.plot([0,1],[0,1],'r--')\n",
        "plt.xlim([0.0,1.0])\n",
        "plt.ylim([0.0,1.05])\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('ROC Curve for K-nearest Neighbours Classifier')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sCou2zTALcSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#List Hyperparameters that we want to tune.\n",
        "#leaf_size = list(range(1,50))\n",
        "n_neighbors = list(range(1,30))\n",
        "p=[1,2]\n",
        "#Convert to dictionary\n",
        "#hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
        "#Create new KNN object\n",
        "knn_2 = KNeighborsClassifier()\n",
        "#Use GridSearch\n",
        "#clf = GridSearchCV(knn_2, hyperparameters, cv=10)\n",
        "#Fit the model\n",
        "#best_model = clf.fit(X,y)\n",
        "#Print The value of best Hyperparameters\n",
        "#print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
        "#print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
        "#print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
      ],
      "metadata": {
        "id": "sTfGzsOoaGY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "p6Qj6LLdE_-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Build a Gaussian Classifier\n",
        "model = GaussianNB()\n",
        "\n",
        "# Model training\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict Output\n",
        "predicted = model.predict([X_test[6]])\n",
        "\n",
        "#print(\"Actual Value:\", y_test[6])\n",
        "#print(\"Predicted Value:\", predicted[0])"
      ],
      "metadata": {
        "id": "es7rRFZP3ws-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    f1_score,\n",
        ")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuray = accuracy_score(y_pred, y_test)\n",
        "f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#print(\"Accuracy:\", accuray)\n",
        "#print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "id": "9MzrVr08395y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model's performance using a confusion matrix\n",
        "cm_nb = confusion_matrix(y_test, y_pred)\n",
        "print(cm_nb)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "L1SXtqEe4OxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model's performance using a heatmap using the confusion matrix scores\n",
        "sns.set (rc = {'figure.figsize':(4, 4)})\n",
        "sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues', cbar=False)"
      ],
      "metadata": {
        "id": "SOkMA9gF3wwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bf1Qcc3FHSBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation of the models's performance on an ROC/AUC curve\n",
        "plt.figure(figsize=(5,4))\n",
        "y_pred_proba = model.predict_proba(X_test)[:,1]\n",
        "fpr, tpr, thresholds = roc_curve(y_test,  y_pred_proba)\n",
        "nb_roc_auc2=roc_auc_score(y_test,model.predict(X_test))\n",
        "plt.plot(fpr, tpr, label='Naive Bayes Classifier')\n",
        "plt.plot([0,1],[0,1],'r--')\n",
        "plt.xlim([0.0,1.0])\n",
        "plt.ylim([0.0,1.05])\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('ROC Curve for Naive Bayes Classifier')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gx6G5Bnzxz6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the predictions to a CSV file\n",
        "output_df.to_csv('predictions_output.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "0wZwE8MLujh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = pd.DataFrame({\n",
        "    'Model': ['Support Vector Machines','Linear Regression', 'KNN','Naive Bayes'],\n",
        "   'Score': [acc_svc,  rmse, acc_knn ,acc_gaussian]})\n",
        "models.sort_values(by='Score', ascending=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "DvjRq6XZxbJb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}